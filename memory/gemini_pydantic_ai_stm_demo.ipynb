{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec4b7a3",
   "metadata": {},
   "source": [
    "\n",
    "# Gemini + Pydantic AI + Short-Term Memory (Notebook Demo)\n",
    "\n",
    "This notebook shows how to:\n",
    "- Maintain **short-term conversation memory** with a small in-memory store\n",
    "- Build a **Pydantic AI** Agent using **Gemini**\n",
    "- Run a mini loop that reuses memory between turns\n",
    "\n",
    "> Before running the agent cell, set `GOOGLE_API_KEY` in your environment (or `os.environ` in a cell).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5a6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Optional: install deps (uncomment if you need)\n",
    "# %pip install pydantic-ai google-generativeai httpx\n",
    "# If you're using the \"slim\" build & tools:\n",
    "# %pip install \"pydantic-ai-slim\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce80985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STM ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from typing import List, Dict, Optional, Any\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---- Minimal STM (In-memory) ----\n",
    "class Turn:\n",
    "    def __init__(self, role: str, content: str, meta: Optional[Dict[str, Any]] = None):\n",
    "        self.role = role\n",
    "        self.content = content\n",
    "        self.meta = meta or {}\n",
    "        self.created_at = datetime.utcnow().isoformat()\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\"role\": self.role, \"content\": self.content, \"meta\": self.meta, \"created_at\": self.created_at}\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    if not text:\n",
    "        return 0\n",
    "    return max(1, int(len(text) / 4))\n",
    "\n",
    "class InMemoryShortTermMemory:\n",
    "    def __init__(self, max_turns_per_session: int = 500, default_ttl_sec: int = 3600):\n",
    "        self.store: Dict[str, List[Dict[str, Any]]] = {}\n",
    "        self.expiry: Dict[str, datetime] = {}\n",
    "        self.max_turns = max_turns_per_session\n",
    "        self.default_ttl = default_ttl_sec\n",
    "\n",
    "    def _expired(self, sid: str) -> bool:\n",
    "        exp = self.expiry.get(sid)\n",
    "        return exp is not None and datetime.utcnow() > exp\n",
    "\n",
    "    def _gc(self, sid: str):\n",
    "        if self._expired(sid):\n",
    "            self.store.pop(sid, None)\n",
    "            self.expiry.pop(sid, None)\n",
    "\n",
    "    def append_turn(self, session_id: str, role: str, content: str, meta: Optional[Dict[str, Any]] = None, ttl_sec: Optional[int] = None):\n",
    "        self._gc(session_id)\n",
    "        lst = self.store.setdefault(session_id, [])\n",
    "        lst.append(Turn(role, content, meta).to_dict())\n",
    "        if len(lst) > self.max_turns:\n",
    "            del lst[0: len(lst) - self.max_turns]\n",
    "        self.expiry[session_id] = datetime.utcnow() + timedelta(seconds=ttl_sec or self.default_ttl)\n",
    "\n",
    "    def get_all(self, session_id: str) -> List[Dict[str, Any]]:\n",
    "        self._gc(session_id)\n",
    "        return list(self.store.get(session_id, []))\n",
    "\n",
    "    def get_by_token_budget(self, session_id: str, max_tokens: int = 2000) -> List[Dict[str, Any]]:\n",
    "        turns = self.get_all(session_id)\n",
    "        acc = []\n",
    "        running = 0\n",
    "        for t in reversed(turns):\n",
    "            t_tokens = estimate_tokens(t[\"content\"])\n",
    "            if running + t_tokens > max_tokens and acc:\n",
    "                break\n",
    "            if running + t_tokens > max_tokens and not acc:\n",
    "                acc.append(t); break\n",
    "            acc.append(t); running += t_tokens\n",
    "        return list(reversed(acc))\n",
    "    \n",
    "    def to_prompt_lines(self, session_id: str, max_tokens: int = 2000) -> str:\n",
    "        lines = []\n",
    "        for t in self.get_by_token_budget(session_id, max_tokens=max_tokens):\n",
    "            lines.append(f\"[{t['role']}] {t['content']}\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "stm = InMemoryShortTermMemory()\n",
    "print(\"STM ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20df7353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ready: google-gla:gemini-2.5-pro\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pydantic_ai import Agent, RunContext, ModelSettings\n",
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "# Use a light model for speed; change to gemini-1.5-pro if you prefer\n",
    "MODEL_ID = \"google-gla:gemini-2.5-pro\"\n",
    "if os.getenv(\"GOOGLE_API_KEY\") is None:\n",
    "    print(\"⚠️ Set GOOGLE_API_KEY in your environment before running the next cell.\")\n",
    "\n",
    "# --- Agent definition ---\n",
    "ai_data_analyst = Agent[str, str](\n",
    "    MODEL_ID,\n",
    "    deps_type=str,            # we'll pass a 'session_id' as the dependency\n",
    "    output_type=str,\n",
    "    instructions=(\n",
    "        \"You are a precise data-analyst assistant. \"\n",
    "        \"Use the provided memory recap to stay consistent with the user's prior context. \"\n",
    "        \"When you need clarification, ask concise follow-ups. \"\n",
    "        \"Prefer structured, bullet-point answers with clear steps or queries.\"\n",
    "    ),\n",
    "    # model_settings=ModelSettings(temperature=0.2, max_tokens=500),\n",
    ")\n",
    "\n",
    "@ai_data_analyst.system_prompt\n",
    "def memory_recap(ctx: RunContext[str]) -> str:\n",
    "    \"\"\"Inject a short memory recap built from STM for this session.\"\"\"\n",
    "    session_id = ctx.deps  # deps is our session_id string\n",
    "    recap = stm.to_prompt_lines(session_id, max_tokens=1200)\n",
    "    if recap.strip():\n",
    "        return (\"Conversation memory (most recent first consolidated for context). \"\n",
    "                \"Use for reference only, don't repeat verbatim.\\n\\n\" + recap)\n",
    "    else:\n",
    "        return \"No prior memory for this session.\"\n",
    "\n",
    "# A tiny tool to show how you'd hook DB/metrics calls.\n",
    "@ai_data_analyst.tool\n",
    "def echo_last_user(ctx: RunContext[str], n: int = 1) -> str:\n",
    "    \"\"\"Return the last n user turns from STM (for debugging/demo).\"\"\"\n",
    "    session_id = ctx.deps\n",
    "    turns = [t for t in stm.get_all(session_id) if t[\"role\"] == \"user\"]\n",
    "    if not turns:\n",
    "        return \"No user turns yet.\"\n",
    "    sel = turns[-n:]\n",
    "    return \"\\n\".join(f\"{i+1}. {t['content']}\" for i, t in enumerate(sel))\n",
    "\n",
    "print(\"Agent ready:\", MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e4e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic_ai.models.google import GoogleModelSettings\n",
    "\n",
    "async def ask_async(session_id: str, user_question: str, google_settings: Optional[GoogleModelSettings] = None) -> str:\n",
    "    # record user turn\n",
    "    stm.append_turn(session_id, \"user\", user_question)\n",
    "\n",
    "    # run the agent asynchronously so we don't collide with Jupyter's event loop\n",
    "    result = await ai_data_analyst.run(\n",
    "        user_question,\n",
    "        deps=session_id,\n",
    "        model_settings=google_settings or GoogleModelSettings(temperature=0.2)\n",
    "    )\n",
    "\n",
    "    # record assistant turn\n",
    "    stm.append_turn(\n",
    "        session_id,\n",
    "        \"assistant\",\n",
    "        result.output,\n",
    "        # meta={\"model\": result.model, \"usage\": result.usage().model_dump()}\n",
    "    )\n",
    "\n",
    "    # usage = result.usage()\n",
    "    # print(f\"[model={result.model_name}] tokens in={usage.input_tokens} out={usage.output_tokens}\")\n",
    "    return result.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a331a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1\n",
      "Got it, TJ. Lasagna is a great choice\n",
      "\n",
      "Q2\n",
      "You said your name is TJ.\n",
      "\n",
      "Q3 (uses tool)\n",
      "You said your favorite food is lasagna.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"demo-session-001\"\n",
    "\n",
    "print(\"Q1\")\n",
    "print(await ask_async(session_id, \"My name is TJ and my favourite food is lasagna.\"))\n",
    "\n",
    "print(\"\\nQ2\")\n",
    "print(await ask_async(session_id, \"What did I say my name was?\"))\n",
    "\n",
    "print(\"\\nQ3 (uses tool)\")\n",
    "print(await ask_async(session_id, \"What is my favourite food?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550fd5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pydantic (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
